# Example Ansible Inventory for HSI Compression
# Copy this file and customize with your actual machine credentials

[gpu_servers]
# Example GPU machines (uncomment and modify with your actual machines)
# Format: hostname ansible_host=IP_or_hostname ansible_user=username [ansible_port=port] ansible_ssh_private_key_file=path_to_key
# Note: ansible_port is optional. Default is 22. Use custom ports like vast.ai's forwarded ports.

# AWS EC2 Example (default port 22)
# aws-gpu-1 ansible_host=54.123.45.67 ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/aws-key.pem

# vast.ai Example (custom port)
# vast-gpu-1 ansible_host=1.2.3.4 ansible_user=root ansible_port=32369 ansible_ssh_private_key_file=~/.ssh/vast-key

# On-premise Example (custom port)
# lab-gpu-1 ansible_host=192.168.1.100 ansible_user=researcher ansible_port=2222 ansible_ssh_private_key_file=~/.ssh/lab-key

# Local machine (for testing)
# localhost ansible_connection=local ansible_python_interpreter={{ ansible_playbook_python }}

[dev_servers]
# Development/testing machines
# dev-machine ansible_host=192.168.1.50 ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/id_rsa

[all:vars]
# ============================================================
# Global Configuration (applies to all hosts unless overridden)
# ============================================================

# Python configuration
ansible_python_interpreter=/usr/bin/python3
python_version=3.10

# SSH configuration
ansible_connection=ssh
ansible_port=22  # Default SSH port (can be overridden per host with ansible_port=XXXX)
ansible_timeout=30

# Project configuration
project_name=hsi-compression
project_dir=/home/{{ ansible_user }}/{{ project_name }}
venv_dir={{ project_dir }}/venv

# Git configuration
git_repo=https://github.com/yourusername/hsi-compression.git
git_branch=main

# Dataset configuration
dataset_name=hyspecnet11k
dataset_path={{ project_dir }}/data/{{ dataset_name }}
pull_dataset_script=pull_dataset
dataset_pull_args=  # Optional: add arguments like "--split train val"

# Training directories
checkpoint_dir={{ project_dir }}/checkpoints
logs_dir={{ project_dir }}/logs
results_dir={{ project_dir }}/results

# GPU/CUDA configuration
enable_cuda=true
cuda_version=11.8
cudnn_version=8.6

# WandB configuration (set to true to enable experiment tracking)
wandb_enabled=false
# wandb_api_key=your-api-key-here  # Uncomment and set your API key
# wandb_project=hsi-compression     # Optional: custom project name

# Training defaults (can be overridden per playbook run)
model_name=tcn_lossless
training_epochs=100
batch_size=8
learning_rate=0.0001
run_async=false
training_timeout=86400  # 24 hours in seconds

# Slack notifications (optional)
enable_slack_notifications=false
# slack_webhook_url=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# ============================================================
# Per-host configuration examples (uncomment and customize)
# ============================================================

[gpu_servers:vars]
# Override global settings specifically for GPU servers
enable_cuda=true
wandb_enabled=false

[dev_servers:vars]
# Override settings for dev servers
enable_cuda=false
python_version=3.9

# ============================================================
# Host-specific variables (create separate files if needed)
# ============================================================

# For more complex per-host configuration, create files in host_vars/
# Example: host_vars/gpu-server-1.yml
# 
# ---
# wandb_enabled: true
# wandb_api_key: "your-secret-key"
# wandb_project: "hsi-compression-exp1"
# cuda_version: 12.0
# training_epochs: 200
